{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Feature enginerring - SelectKbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%run talibref.py\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available data: Ticker(ITB) from 2006.05.05 to 2015.11.27\n",
      "Usable data: Ticker(ITB) from 2007.02.22 to 2015.11.27 \n",
      "Returned data: Ticker(ITB) from 2010.01.04 to 2015.11.27 \n",
      "Save path: data/ITB_from_2010.01.04_2015.11.27.csv\n"
     ]
    }
   ],
   "source": [
    "#df=pd.read_csv(\"data/IYZ.csv\")\n",
    "ticker = 'ITB'\n",
    "startdate=datetime.date(2010, 1, 1)\n",
    "enddate=datetime.date.today()\n",
    "df = generate_ticker_data(ticker, startdate, enddate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dftouse=df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IGNORE = ['date', 'result_1','close_1','perf_1','result_14','close_14','perf_14','results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "INDICATORS=[]\n",
    "for v in df.columns:\n",
    "    l=df[v].unique()\n",
    "    if len(l) <= 10 and v not in IGNORE:\n",
    "        #print v, l\n",
    "        INDICATORS.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STANDARDIZABLE = []\n",
    "for v in df.columns:\n",
    "    if v not in INDICATORS and v not in IGNORE:\n",
    "        #print v\n",
    "        STANDARDIZABLE.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1487,), 1258)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftouse['date'] = pd.to_datetime(dftouse['date'])\n",
    "mask = (dftouse.date < '2015-01-01').values\n",
    "mask.shape, mask.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Standardize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the mask to compute the training and test parts of the dataframe. Use `StandardScaler` from `sklearn.preprocessing` to \"fit\" the columns in `STANDARDIZABLE` on the training set. Then use the resultant estimator to transform both the training and the test parts of each of the columns in the dataframe, replacing the old unstandardized values in the `STANDARDIZABLE` columns of `dftouse` by the new standardized ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>close_1</th>\n",
       "      <th>result_1</th>\n",
       "      <th>perf_1</th>\n",
       "      <th>close_14</th>\n",
       "      <th>result_14</th>\n",
       "      <th>perf_14</th>\n",
       "      <th>results</th>\n",
       "      <th>bb_upper</th>\n",
       "      <th>bb_middle</th>\n",
       "      <th>bb_lower</th>\n",
       "      <th>bb_pct</th>\n",
       "      <th>bb_bandwidth</th>\n",
       "      <th>bb_squeeze</th>\n",
       "      <th>bb_signalup</th>\n",
       "      <th>bb_signaldn</th>\n",
       "      <th>bb_signal</th>\n",
       "      <th>ema50</th>\n",
       "      <th>ema150</th>\n",
       "      <th>ema200</th>\n",
       "      <th>ema_signal1</th>\n",
       "      <th>ema_signal2</th>\n",
       "      <th>kama50</th>\n",
       "      <th>kama150</th>\n",
       "      <th>kama200</th>\n",
       "      <th>kama_signal1</th>\n",
       "      <th>kama_signal2</th>\n",
       "      <th>sar</th>\n",
       "      <th>sar_signal</th>\n",
       "      <th>adx</th>\n",
       "      <th>plus_di</th>\n",
       "      <th>minus_di</th>\n",
       "      <th>adx_trend</th>\n",
       "      <th>adx_direction</th>\n",
       "      <th>adx_signal</th>\n",
       "      <th>aroon_osc</th>\n",
       "      <th>aroon_signal</th>\n",
       "      <th>cci</th>\n",
       "      <th>cci_signal</th>\n",
       "      <th>macd</th>\n",
       "      <th>macd_sigline</th>\n",
       "      <th>macd_hist</th>\n",
       "      <th>macd_signal</th>\n",
       "      <th>ppo</th>\n",
       "      <th>ppo_signal</th>\n",
       "      <th>mfi</th>\n",
       "      <th>mfi_signal</th>\n",
       "      <th>roc</th>\n",
       "      <th>roc_signal</th>\n",
       "      <th>rsi</th>\n",
       "      <th>rsi_signal</th>\n",
       "      <th>ult_osc</th>\n",
       "      <th>ult_signal</th>\n",
       "      <th>willr</th>\n",
       "      <th>wr_signal</th>\n",
       "      <th>ad_osc</th>\n",
       "      <th>ad_signal</th>\n",
       "      <th>stoch_slowk</th>\n",
       "      <th>stoch_slowd</th>\n",
       "      <th>sslow_signal</th>\n",
       "      <th>stoch_fastk</th>\n",
       "      <th>stoch_fastd</th>\n",
       "      <th>srsi_signal</th>\n",
       "      <th>trix</th>\n",
       "      <th>trix_signal</th>\n",
       "      <th>sr_pivotpts</th>\n",
       "      <th>sr_res1</th>\n",
       "      <th>sr_sup1</th>\n",
       "      <th>sr_res2</th>\n",
       "      <th>sr_sup2</th>\n",
       "      <th>sr_res3</th>\n",
       "      <th>sr_sup3</th>\n",
       "      <th>cv_signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>-1.055232</td>\n",
       "      <td>-1.056582</td>\n",
       "      <td>-1.042337</td>\n",
       "      <td>-1.030790</td>\n",
       "      <td>-0.616430</td>\n",
       "      <td>12.27</td>\n",
       "      <td>True</td>\n",
       "      <td>0.009046</td>\n",
       "      <td>12.15</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000822</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.112213</td>\n",
       "      <td>-1.099606</td>\n",
       "      <td>-1.080306</td>\n",
       "      <td>0.800161</td>\n",
       "      <td>0.088232</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.064873</td>\n",
       "      <td>-1.053642</td>\n",
       "      <td>-1.028230</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.996363</td>\n",
       "      <td>-1.036326</td>\n",
       "      <td>-1.118015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.087456</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.763132</td>\n",
       "      <td>-0.447355</td>\n",
       "      <td>-0.952848</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571202</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417710</td>\n",
       "      <td>0</td>\n",
       "      <td>0.158613</td>\n",
       "      <td>-0.039646</td>\n",
       "      <td>0.587714</td>\n",
       "      <td>1</td>\n",
       "      <td>0.770558</td>\n",
       "      <td>1</td>\n",
       "      <td>2.155632</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666324</td>\n",
       "      <td>0</td>\n",
       "      <td>0.576373</td>\n",
       "      <td>0</td>\n",
       "      <td>0.772608</td>\n",
       "      <td>0</td>\n",
       "      <td>0.764450</td>\n",
       "      <td>0</td>\n",
       "      <td>0.361341</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.865794</td>\n",
       "      <td>-0.655599</td>\n",
       "      <td>0</td>\n",
       "      <td>1.180050</td>\n",
       "      <td>-0.415780</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.699566</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.043468</td>\n",
       "      <td>-1.054074</td>\n",
       "      <td>-0.909982</td>\n",
       "      <td>-1.166004</td>\n",
       "      <td>-0.876922</td>\n",
       "      <td>-1.160626</td>\n",
       "      <td>-0.723936</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>-1.023336</td>\n",
       "      <td>-1.036093</td>\n",
       "      <td>-1.044227</td>\n",
       "      <td>-1.010147</td>\n",
       "      <td>-0.878796</td>\n",
       "      <td>12.26</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000815</td>\n",
       "      <td>12.16</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.008965</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.100090</td>\n",
       "      <td>-1.092604</td>\n",
       "      <td>-1.078782</td>\n",
       "      <td>0.917897</td>\n",
       "      <td>0.173550</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.061762</td>\n",
       "      <td>-1.052063</td>\n",
       "      <td>-1.027100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.996236</td>\n",
       "      <td>-1.035286</td>\n",
       "      <td>-1.115500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.075170</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.704336</td>\n",
       "      <td>-0.317347</td>\n",
       "      <td>-1.181922</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571202</td>\n",
       "      <td>1</td>\n",
       "      <td>0.525116</td>\n",
       "      <td>0</td>\n",
       "      <td>0.210364</td>\n",
       "      <td>0.013771</td>\n",
       "      <td>0.594222</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844688</td>\n",
       "      <td>1</td>\n",
       "      <td>2.176495</td>\n",
       "      <td>0</td>\n",
       "      <td>0.945762</td>\n",
       "      <td>0</td>\n",
       "      <td>0.798681</td>\n",
       "      <td>0</td>\n",
       "      <td>1.218399</td>\n",
       "      <td>0</td>\n",
       "      <td>1.068674</td>\n",
       "      <td>0</td>\n",
       "      <td>0.409022</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.031562</td>\n",
       "      <td>-0.625546</td>\n",
       "      <td>0</td>\n",
       "      <td>1.180050</td>\n",
       "      <td>0.501045</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.663429</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.030332</td>\n",
       "      <td>-1.029722</td>\n",
       "      <td>-0.883741</td>\n",
       "      <td>-1.153940</td>\n",
       "      <td>-0.862829</td>\n",
       "      <td>-1.138260</td>\n",
       "      <td>-0.696166</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>-1.010202</td>\n",
       "      <td>-1.028642</td>\n",
       "      <td>-0.995105</td>\n",
       "      <td>-1.012024</td>\n",
       "      <td>-0.956545</td>\n",
       "      <td>12.97</td>\n",
       "      <td>True</td>\n",
       "      <td>0.057912</td>\n",
       "      <td>12.20</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.004894</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.090567</td>\n",
       "      <td>-1.084751</td>\n",
       "      <td>-1.072744</td>\n",
       "      <td>0.795378</td>\n",
       "      <td>0.198502</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.058849</td>\n",
       "      <td>-1.050532</td>\n",
       "      <td>-1.026002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.996158</td>\n",
       "      <td>-1.034116</td>\n",
       "      <td>-1.113499</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.064112</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.629103</td>\n",
       "      <td>-0.288024</td>\n",
       "      <td>-1.268094</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571202</td>\n",
       "      <td>1</td>\n",
       "      <td>0.762325</td>\n",
       "      <td>0</td>\n",
       "      <td>0.242766</td>\n",
       "      <td>0.063485</td>\n",
       "      <td>0.552872</td>\n",
       "      <td>1</td>\n",
       "      <td>0.907703</td>\n",
       "      <td>1</td>\n",
       "      <td>2.174899</td>\n",
       "      <td>0</td>\n",
       "      <td>0.676140</td>\n",
       "      <td>0</td>\n",
       "      <td>0.766219</td>\n",
       "      <td>0</td>\n",
       "      <td>1.074731</td>\n",
       "      <td>0</td>\n",
       "      <td>1.021338</td>\n",
       "      <td>0</td>\n",
       "      <td>0.389190</td>\n",
       "      <td>1</td>\n",
       "      <td>0.892584</td>\n",
       "      <td>-0.000569</td>\n",
       "      <td>0</td>\n",
       "      <td>1.040781</td>\n",
       "      <td>1.430617</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.625537</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.012193</td>\n",
       "      <td>-0.996094</td>\n",
       "      <td>-0.847503</td>\n",
       "      <td>-1.137281</td>\n",
       "      <td>-0.843366</td>\n",
       "      <td>-1.107375</td>\n",
       "      <td>-0.657817</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>-0.982058</td>\n",
       "      <td>-0.892667</td>\n",
       "      <td>-0.949762</td>\n",
       "      <td>-0.878780</td>\n",
       "      <td>-0.460615</td>\n",
       "      <td>12.98</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>12.34</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.048574</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.054919</td>\n",
       "      <td>-1.068570</td>\n",
       "      <td>-1.077332</td>\n",
       "      <td>1.814589</td>\n",
       "      <td>0.523193</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.050700</td>\n",
       "      <td>-1.047127</td>\n",
       "      <td>-1.023448</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.993258</td>\n",
       "      <td>-1.030532</td>\n",
       "      <td>-1.109175</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.054160</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.316392</td>\n",
       "      <td>1.752071</td>\n",
       "      <td>-1.649977</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1.023908</td>\n",
       "      <td>1</td>\n",
       "      <td>2.277120</td>\n",
       "      <td>0</td>\n",
       "      <td>0.460397</td>\n",
       "      <td>0.150145</td>\n",
       "      <td>0.965456</td>\n",
       "      <td>1</td>\n",
       "      <td>1.084186</td>\n",
       "      <td>1</td>\n",
       "      <td>2.264355</td>\n",
       "      <td>0</td>\n",
       "      <td>1.112054</td>\n",
       "      <td>0</td>\n",
       "      <td>1.849200</td>\n",
       "      <td>0</td>\n",
       "      <td>2.261381</td>\n",
       "      <td>0</td>\n",
       "      <td>1.280418</td>\n",
       "      <td>0</td>\n",
       "      <td>0.505646</td>\n",
       "      <td>1</td>\n",
       "      <td>1.438334</td>\n",
       "      <td>0.836531</td>\n",
       "      <td>0</td>\n",
       "      <td>1.180050</td>\n",
       "      <td>1.430617</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.577834</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.907109</td>\n",
       "      <td>-0.801281</td>\n",
       "      <td>-0.763156</td>\n",
       "      <td>-0.925308</td>\n",
       "      <td>-0.865513</td>\n",
       "      <td>-0.821418</td>\n",
       "      <td>-0.701455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>-0.878864</td>\n",
       "      <td>-0.900118</td>\n",
       "      <td>-0.872301</td>\n",
       "      <td>-0.876903</td>\n",
       "      <td>-0.578370</td>\n",
       "      <td>12.95</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.002311</td>\n",
       "      <td>12.35</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.048536</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.026854</td>\n",
       "      <td>-1.052295</td>\n",
       "      <td>-1.073670</td>\n",
       "      <td>1.543695</td>\n",
       "      <td>0.712971</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.042794</td>\n",
       "      <td>-1.043740</td>\n",
       "      <td>-1.020900</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.989863</td>\n",
       "      <td>-1.026844</td>\n",
       "      <td>-1.105159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.028427</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.026017</td>\n",
       "      <td>1.494864</td>\n",
       "      <td>-1.724919</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1.023908</td>\n",
       "      <td>1</td>\n",
       "      <td>2.031605</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625489</td>\n",
       "      <td>0.255041</td>\n",
       "      <td>1.169113</td>\n",
       "      <td>1</td>\n",
       "      <td>1.244347</td>\n",
       "      <td>1</td>\n",
       "      <td>2.316430</td>\n",
       "      <td>0</td>\n",
       "      <td>1.094578</td>\n",
       "      <td>0</td>\n",
       "      <td>1.860484</td>\n",
       "      <td>0</td>\n",
       "      <td>2.401756</td>\n",
       "      <td>0</td>\n",
       "      <td>1.301636</td>\n",
       "      <td>0</td>\n",
       "      <td>0.607788</td>\n",
       "      <td>1</td>\n",
       "      <td>1.417438</td>\n",
       "      <td>1.362959</td>\n",
       "      <td>0</td>\n",
       "      <td>1.180050</td>\n",
       "      <td>1.430617</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.522454</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.883340</td>\n",
       "      <td>-0.757217</td>\n",
       "      <td>-0.715671</td>\n",
       "      <td>-0.903479</td>\n",
       "      <td>-0.840011</td>\n",
       "      <td>-0.780947</td>\n",
       "      <td>-0.651205</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date      open      high       low     close    volume  close_1 result_1    perf_1  close_14 result_14   perf_14  results  bb_upper  bb_middle  bb_lower    bb_pct  bb_bandwidth bb_squeeze bb_signalup bb_signaldn  bb_signal     ema50    ema150    ema200  ema_signal1  ema_signal2    kama50   kama150   kama200  kama_signal1  kama_signal2       sar  sar_signal       adx   plus_di  minus_di adx_trend adx_direction  adx_signal  aroon_osc  aroon_signal       cci  cci_signal      macd  \\\n",
       "0 2010-01-04 -1.055232 -1.056582 -1.042337 -1.030790 -0.616430    12.27     True  0.009046     12.15     False -0.000822        1 -1.112213  -1.099606 -1.080306  0.800161      0.088232      False       False       False          1 -1.064873 -1.053642 -1.028230            1            1 -0.996363 -1.036326 -1.118015             1             1 -1.087456           1 -0.763132 -0.447355 -0.952848     False          True           0   0.571202             1  0.417710           0  0.158613   \n",
       "1 2010-01-05 -1.023336 -1.036093 -1.044227 -1.010147 -0.878796    12.26    False -0.000815     12.16     False -0.008965        1 -1.100090  -1.092604 -1.078782  0.917897      0.173550      False       False       False          1 -1.061762 -1.052063 -1.027100            1            1 -0.996236 -1.035286 -1.115500             1             1 -1.075170           1 -0.704336 -0.317347 -1.181922     False          True           0   0.571202             1  0.525116           0  0.210364   \n",
       "2 2010-01-06 -1.010202 -1.028642 -0.995105 -1.012024 -0.956545    12.97     True  0.057912     12.20     False -0.004894        1 -1.090567  -1.084751 -1.072744  0.795378      0.198502      False       False       False          1 -1.058849 -1.050532 -1.026002            1            1 -0.996158 -1.034116 -1.113499             1             1 -1.064112           1 -0.629103 -0.288024 -1.268094     False          True           0   0.571202             1  0.762325           0  0.242766   \n",
       "3 2010-01-07 -0.982058 -0.892667 -0.949762 -0.878780 -0.460615    12.98     True  0.000771     12.34     False -0.048574        0 -1.054919  -1.068570 -1.077332  1.814589      0.523193      False        True       False          1 -1.050700 -1.047127 -1.023448            1            1 -0.993258 -1.030532 -1.109175             1             1 -1.054160           1 -0.316392  1.752071 -1.649977     False          True           0   1.023908             1  2.277120           0  0.460397   \n",
       "4 2010-01-08 -0.878864 -0.900118 -0.872301 -0.876903 -0.578370    12.95    False -0.002311     12.35     False -0.048536        0 -1.026854  -1.052295 -1.073670  1.543695      0.712971      False        True       False          1 -1.042794 -1.043740 -1.020900            1            1 -0.989863 -1.026844 -1.105159             1             1 -1.028427           1 -0.026017  1.494864 -1.724919     False          True           0   1.023908             1  2.031605           0  0.625489   \n",
       "\n",
       "   macd_sigline  macd_hist  macd_signal       ppo  ppo_signal       mfi  mfi_signal       roc  roc_signal       rsi  rsi_signal   ult_osc  ult_signal     willr  wr_signal    ad_osc  ad_signal  stoch_slowk  stoch_slowd  sslow_signal  stoch_fastk  stoch_fastd  srsi_signal      trix  trix_signal  sr_pivotpts   sr_res1   sr_sup1   sr_res2   sr_sup2   sr_res3   sr_sup3  cv_signal  \n",
       "0     -0.039646   0.587714            1  0.770558           1  2.155632           0  0.666324           0  0.576373           0  0.772608           0  0.764450          0  0.361341          1    -0.865794    -0.655599             0     1.180050    -0.415780            0 -0.699566            0    -1.043468 -1.054074 -0.909982 -1.166004 -0.876922 -1.160626 -0.723936          0  \n",
       "1      0.013771   0.594222            1  0.844688           1  2.176495           0  0.945762           0  0.798681           0  1.218399           0  1.068674          0  0.409022          1    -0.031562    -0.625546             0     1.180050     0.501045            0 -0.663429            0    -1.030332 -1.029722 -0.883741 -1.153940 -0.862829 -1.138260 -0.696166          0  \n",
       "2      0.063485   0.552872            1  0.907703           1  2.174899           0  0.676140           0  0.766219           0  1.074731           0  1.021338          0  0.389190          1     0.892584    -0.000569             0     1.040781     1.430617            0 -0.625537            0    -1.012193 -0.996094 -0.847503 -1.137281 -0.843366 -1.107375 -0.657817          0  \n",
       "3      0.150145   0.965456            1  1.084186           1  2.264355           0  1.112054           0  1.849200           0  2.261381           0  1.280418          0  0.505646          1     1.438334     0.836531             0     1.180050     1.430617            0 -0.577834            0    -0.907109 -0.801281 -0.763156 -0.925308 -0.865513 -0.821418 -0.701455          0  \n",
       "4      0.255041   1.169113            1  1.244347           1  2.316430           0  1.094578           0  1.860484           0  2.401756           0  1.301636          0  0.607788          1     1.417438     1.362959             0     1.180050     1.430617            0 -0.522454            0    -0.883340 -0.757217 -0.715671 -0.903479 -0.840011 -0.780947 -0.651205          1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code here\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(dftouse[mask][STANDARDIZABLE])\n",
    "dftouse[STANDARDIZABLE] = scaler.transform(dftouse[STANDARDIZABLE])\n",
    "dftouse.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a list `lcols` of the columns we will use in our classifier. This list should not contain the response `RESP`. How many features do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "#lcols=list(dftouse.columns)\n",
    "#lcols.remove(u'results')\n",
    "lcols=[]\n",
    "for c in list(dftouse.columns):\n",
    "    if c not in IGNORE: \n",
    "        lcols.append(c)\n",
    "print len(lcols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA for the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We create a variable `ccols` which contains all variables not in our indicators list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 26\n"
     ]
    }
   ],
   "source": [
    "ccols=[]\n",
    "for c in lcols:\n",
    "    if c not in INDICATORS and c not in IGNORE:\n",
    "        ccols.append(c)\n",
    "print len(ccols), len(INDICATORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_optimize(clf, parameters, X, y, n_folds, score_func):\n",
    "    fitmodel = GridSearchCV(clf, param_grid=parameters, cv=n_folds, scoring=score_func)\n",
    "    fitmodel.fit(X, y)\n",
    "    return fitmodel.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def do_classify(clf, parameters, indf, featurenames, targetname, target1val, mask=None, reuse_split=None, score_func=None, n_folds=5):\n",
    "    subdf=indf[featurenames]\n",
    "    X=subdf.values\n",
    "    y=(indf[targetname].values==target1val)*1\n",
    "    if mask !=None:\n",
    "        #print \"using mask\"\n",
    "        Xtrain, Xtest, ytrain, ytest = X[mask], X[~mask], y[mask], y[~mask]\n",
    "    if reuse_split !=None:\n",
    "        #print \"using reuse split\"\n",
    "        Xtrain, Xtest, ytrain, ytest = reuse_split['Xtrain'], reuse_split['Xtest'], reuse_split['ytrain'], reuse_split['ytest']\n",
    "    if parameters:\n",
    "        clf = cv_optimize(clf, parameters, Xtrain, ytrain, n_folds=n_folds, score_func=score_func)\n",
    "    clf=clf.fit(Xtrain, ytrain)\n",
    "    training_accuracy = clf.score(Xtrain, ytrain)\n",
    "    test_accuracy = clf.score(Xtest, ytest)\n",
    "    #print \"############# based on standard predict ################\"\n",
    "    #print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
    "    #print \"Accuracy on test data:     %0.2f\" % (test_accuracy)\n",
    "    #print confusion_matrix(ytest, clf.predict(Xtest))\n",
    "    #print \"########################################################\"\n",
    "    return clf, Xtrain, ytrain, Xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=dftouse[lcols].values\n",
    "y=dftouse['results'].values\n",
    "Xtrain, Xtest, ytrain, ytest = X[mask], X[~mask], y[mask], y[~mask]  \n",
    "reuse_split=dict(Xtrain=Xtrain, Xtest=Xtest, ytrain=ytrain, ytest=ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whole data set 0.486213853396\n",
      "training set 0.484101748808 test set 0.497816593886\n"
     ]
    }
   ],
   "source": [
    "print \"whole data set\", dftouse['results'].mean()\n",
    "print \"training set\", dftouse['results'][mask].mean(), \"test set\", dftouse['results'][~mask].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####our data is not very asymmetric, but we might still want to balance the trainset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing train set to test set for training, \n",
    "### intended to be used with SVM only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "609 649\n",
      "(1218, 70) (1218,)\n"
     ]
    }
   ],
   "source": [
    "jtrain=np.arange(0, ytrain.shape[0])\n",
    "n_pos=len(jtrain[ytrain==1])\n",
    "n_neg=len(jtrain[ytrain==0])\n",
    "print n_pos, n_neg\n",
    "\n",
    "ineg = np.random.choice(jtrain[ytrain==0], n_pos, replace=False)\n",
    "alli=np.concatenate((jtrain[ytrain==1], ineg))\n",
    "Xtrain_new = Xtrain[alli]\n",
    "ytrain_new = ytrain[alli]\n",
    "print Xtrain_new.shape, ytrain_new.shape\n",
    "\n",
    "reuse_split_balanced=dict(Xtrain=Xtrain_new, Xtest=Xtest, ytrain=ytrain_new, ytest=ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test all classifiersres using SelectKbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def evaluate(clf):\n",
    "    training_accuracy = clf.score(Xtrain, ytrain)\n",
    "    test_accuracy = clf.score(Xtest, ytest)\n",
    "    df_pred = df[~mask].reset_index(drop=True)\n",
    "    df_pred['pred_result'] = clf.predict(Xtest)\n",
    "    df_pred['result_baseline'] = np.ones(df_pred.shape[0])\n",
    "    _,_,ROI_base,_,_ = evaluate_profit(df_pred, startdate, enddate, 10000, 'result_baseline', 'close', False, [1])\n",
    "    _,_,ROI_long,_,_ = evaluate_profit(df_pred, startdate, enddate, 10000, 'pred_result', 'close', False, [1])\n",
    "    _,_,ROI_lgst,_,_ = evaluate_profit(df_pred, startdate, enddate, 10000, 'pred_result', 'close', False, [1,0])\n",
    "    return training_accuracy, test_accuracy, ROI_base, ROI_long, ROI_lgst\n",
    "\n",
    "def print_result(clfpipe):     \n",
    "    print \"Number of features: {0}\".format(clfpipe.get_params()['selectk__k'])\n",
    "    print \"Features: {0}\".format(np.array(lcols)[clfpipe.named_steps['selectk'].get_support()].tolist())\n",
    "    r = evaluate(clfpipe)\n",
    "    print \"train accuracy: {0}\".format(r[0])\n",
    "    print \"test accuracy: {0}\".format(r[1])\n",
    "    print \"ROI baseline: {0}\".format(r[2])\n",
    "    print \"ROI long-only: {0}\".format(r[3])\n",
    "    print \"ROI long-short: {0}\".format(r[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############====================== Log Regression =====================#############\n",
      "1\n",
      "Number of features: 7\n",
      "Features: ['bb_pct', 'cci', 'rsi', 'ult_osc', 'willr', 'stoch_slowk', 'stoch_slowd']\n",
      "train accuracy: 0.671701112878\n",
      "test accuracy: 0.64192139738\n",
      "ROI baseline: 0.123313\n",
      "ROI long-only: 0.2238699919\n",
      "ROI long-short: 0.3115179793\n",
      "CPU times: user 4.77 s, sys: 71.4 ms, total: 4.84 s\n",
      "Wall time: 5.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_number_featrues = 10 \n",
    "Long_ROI_result={}\n",
    "print \"#############====================== Log Regression =====================#############\"\n",
    "selectk = SelectKBest(score_func=f_regression)\n",
    "pipeLR = Pipeline([('selectk', selectk), ('LR', LogisticRegression(penalty=\"l1\"))])\n",
    "pipeLR, _,_,_,_  = do_classify(pipeLR, {\"selectk__k\":range(1,max_number_featrues+1), \n",
    "                                        \"LR__C\": [1e-3, 1e-2, 1e-1, 1, 1e2]}, \n",
    "                               dftouse,lcols, u'results',1, reuse_split=reuse_split)\n",
    "\n",
    "print pipeLR.get_params()['LR__C']\n",
    "print_result(pipeLR)\n",
    "Long_ROI_result[\"log_regression\"] = evaluate(pipeLR)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############====================== Linear SVM ========================#############\n",
      "1\n",
      "Number of features: 5\n",
      "Features: ['bb_pct', 'cci', 'willr', 'stoch_slowk', 'stoch_slowd']\n",
      "train accuracy: 0.662162162162\n",
      "test accuracy: 0.64192139738\n",
      "ROI baseline: 0.123313\n",
      "ROI long-only: 0.1100111091\n",
      "ROI long-short: 0.0808812102\n",
      "CPU times: user 6.19 s, sys: 111 ms, total: 6.3 s\n",
      "Wall time: 7.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print \"#############====================== Linear SVM ========================#############\"\n",
    "clfsvm_b = Pipeline([('selectk', selectk), ('svm', LinearSVC(loss=\"hinge\"))])\n",
    "clfsvm_b,_,_,_,_  = do_classify(clfsvm_b, {\"selectk__k\":range(1,max_number_featrues+1), \n",
    "                                           \"svm__C\": [1e-300, 1e-200, 1e-100, 1e-10, 1e-1, 1]}, \n",
    "                                dftouse,lcols, u'results',1, reuse_split=reuse_split_balanced)\n",
    "\n",
    "print clfsvm_b.get_params()['svm__C']\n",
    "print_result(clfsvm_b)\n",
    "Long_ROI_result[\"Linear_SVM\"] = evaluate(clfsvm_b)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############====================== RBF SVM ===========================#############\n",
      "1e-100 1e-09\n",
      "Number of features: 2\n",
      "Features: ['bb_pct', 'stoch_slowk']\n",
      "train accuracy: 0.664546899841\n",
      "test accuracy: 0.646288209607\n",
      "ROI baseline: 0.123313\n",
      "ROI long-only: 0.3082939624\n",
      "ROI long-short: 0.4945559228\n",
      "CPU times: user 38.5 s, sys: 367 ms, total: 38.9 s\n",
      "Wall time: 40.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print \"#############====================== RBF SVM ===========================#############\"\n",
    "pipesvm2 = Pipeline([('selectk', selectk), ('svm2', SVC())])\n",
    "pipesvm2,_,_,_,_  = do_classify(pipesvm2, {\"selectk__k\":range(1,max_number_featrues+1), \n",
    "                                            \"svm2__C\": [1e-100, 1e-10, 1e-1, 1, 1e10], \n",
    "                                            \"svm2__gamma\": [ 1e-9, 1e-10, 1e-11]}, \n",
    "                                 dftouse,lcols, u'results',1, reuse_split=reuse_split_balanced)\n",
    "print pipesvm2.get_params()['svm2__C'], pipesvm2.get_params()['svm2__gamma']\n",
    "print_result(pipesvm2)\n",
    "Long_ROI_result[\"RBF_SVM\"] = evaluate(pipesvm2)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print \"#############====================== Random Forest =====================#############\"\n",
    "pipeRF = Pipeline([('selectk', selectk), ('RF', RandomForestClassifier())])\n",
    "pipeRF,_,_,_,_  = do_classify(pipeRF, {\"selectk__k\": [5,6,7,8,9,10],\n",
    "                                       \"RF__max_depth\": [3,5,7,10], \n",
    "                                       \"RF__n_estimators\": [5,10,20,40],\n",
    "                                       \"RF__max_features\": [1,2,3,4,5]}, \n",
    "                              dftouse, lcols, u'results', 1, reuse_split=reuse_split)\n",
    "\n",
    "print pipeRF.get_params()['RF__max_depth'], pipeRF.get_params()['RF__n_estimators'], pipeRF.get_params()['RF__max_features']\n",
    "print_result(pipeRF)\n",
    "Long_ROI_result[\"Random_forest\"] = evaluate(pipeRF)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print \"#############====================== Extra Trees= =====================#############\"\n",
    "pipeET = Pipeline([('selectk', selectk), ('ET', ExtraTreesClassifier())])\n",
    "pipeET, _,_,_,_  = do_classify(pipeET, {\"selectk__k\": [5,6,7,8,9,10],\n",
    "                                        \"ET__max_depth\": [3,5,7,10,15,25,50], \n",
    "                                        \"ET__n_estimators\": [5,10,20,40],\n",
    "                                        \"ET__max_features\": [1,2,3,4,5]}, \n",
    "                               dftouse, lcols, u'results', 1, reuse_split=reuse_split)\n",
    "print \"ET__max_depth: {0}\".format(pipeET.get_params()['ET__max_depth']) \n",
    "print \"ET__n_estimators: {0}\".format(pipeET.get_params()['ET__n_estimators']) \n",
    "print \"ET__max_features: {0}\".format(pipeET.get_params()['ET__max_features']) \n",
    "print_result(pipeET)\n",
    "Long_ROI_result[\"Extra_Trees\"] = evaluate(pipeET)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print \"#############====================== Gaussian NB ==========================#############\"\n",
    "pipeNB = Pipeline([('selectk', selectk), ('NB', GaussianNB())])\n",
    "pipeNB,_,_,_,_ = do_classify(pipeNB, {\"selectk__k\":range(1,max_number_featrues+1)},\n",
    "                             dftouse, lcols, u'results',1, reuse_split=reuse_split)\n",
    "print_result(pipeNB)\n",
    "Long_ROI_result[\"Gaussian_NB\"] = evaluate(pipeNB)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print \"#############====================== Gradient Boosting ====================#############\"\n",
    "pipeGB = Pipeline([('selectk', selectk), ('GB', GradientBoostingClassifier())])\n",
    "pipeGB, _,_,_,_  = do_classify(pipeGB, {\"selectk__k\":range(1,max_number_featrues+1), \n",
    "                                        \"GB__n_estimators\": [5,10,20,40],\n",
    "                                        \"GB__learning_rate\": [0.1,0.5,1.0]}, \n",
    "                               dftouse,lcols, u'results',1, reuse_split=reuse_split)\n",
    "print pipeGB.get_params()['GB__n_estimators'], pipeGB.get_params()['GB__learning_rate']\n",
    "print_result(pipeGB)\n",
    "Long_ROI_result[\"Gradient_bossting\"] = evaluate(pipeGB)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"ROI baseline: {0}\".format(evaluate(pipeGB)[2])\n",
    "Long_ROI_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
