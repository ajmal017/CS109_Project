{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Feature enginerring - SelectKbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%run talibref.py\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available data: Ticker(IYZ) from 2000.05.26 to 2015.11.27\n",
      "Usable data: Ticker(IYZ) from 2001.03.14 to 2015.11.27 \n",
      "Returned data: Ticker(IYZ) from 2010.01.04 to 2015.11.27 \n",
      "Save path: data/IYZ_from_2010.01.04_2015.11.27.csv\n"
     ]
    }
   ],
   "source": [
    "#df=pd.read_csv(\"data/IYZ.csv\")\n",
    "ticker = 'IYZ'\n",
    "startdate=datetime.date(2010, 1, 1)\n",
    "enddate=datetime.date.today()\n",
    "df = generate_ticker_data(ticker, startdate, enddate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dftouse=df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IGNORE = ['date', 'result_1','close_1','perf_1','result_14','close_14','perf_14','results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "INDICATORS=[]\n",
    "for v in df.columns:\n",
    "    l=df[v].unique()\n",
    "    if len(l) <= 10 and v not in IGNORE:\n",
    "        #print v, l\n",
    "        INDICATORS.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STANDARDIZABLE = []\n",
    "for v in df.columns:\n",
    "    if v not in INDICATORS and v not in IGNORE:\n",
    "        #print v\n",
    "        STANDARDIZABLE.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1487L,), 1258)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftouse['date'] = pd.to_datetime(dftouse['date'])\n",
    "mask = (dftouse.date < '2015-01-01').values\n",
    "mask.shape, mask.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Standardize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the mask to compute the training and test parts of the dataframe. Use `StandardScaler` from `sklearn.preprocessing` to \"fit\" the columns in `STANDARDIZABLE` on the training set. Then use the resultant estimator to transform both the training and the test parts of each of the columns in the dataframe, replacing the old unstandardized values in the `STANDARDIZABLE` columns of `dftouse` by the new standardized ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>close_1</th>\n",
       "      <th>result_1</th>\n",
       "      <th>perf_1</th>\n",
       "      <th>close_14</th>\n",
       "      <th>result_14</th>\n",
       "      <th>perf_14</th>\n",
       "      <th>results</th>\n",
       "      <th>bb_upper</th>\n",
       "      <th>bb_middle</th>\n",
       "      <th>bb_lower</th>\n",
       "      <th>bb_pct</th>\n",
       "      <th>bb_bandwidth</th>\n",
       "      <th>bb_squeeze</th>\n",
       "      <th>bb_signalup</th>\n",
       "      <th>bb_signaldn</th>\n",
       "      <th>bb_signal</th>\n",
       "      <th>ema50</th>\n",
       "      <th>ema150</th>\n",
       "      <th>ema200</th>\n",
       "      <th>ema_signal1</th>\n",
       "      <th>ema_signal2</th>\n",
       "      <th>kama50</th>\n",
       "      <th>kama150</th>\n",
       "      <th>kama200</th>\n",
       "      <th>kama_signal1</th>\n",
       "      <th>kama_signal2</th>\n",
       "      <th>sar</th>\n",
       "      <th>sar_signal</th>\n",
       "      <th>adx</th>\n",
       "      <th>plus_di</th>\n",
       "      <th>minus_di</th>\n",
       "      <th>adx_trend</th>\n",
       "      <th>adx_direction</th>\n",
       "      <th>adx_signal</th>\n",
       "      <th>aroon_osc</th>\n",
       "      <th>aroon_signal</th>\n",
       "      <th>cci</th>\n",
       "      <th>cci_signal</th>\n",
       "      <th>macd</th>\n",
       "      <th>macd_sigline</th>\n",
       "      <th>macd_hist</th>\n",
       "      <th>macd_signal</th>\n",
       "      <th>ppo</th>\n",
       "      <th>ppo_signal</th>\n",
       "      <th>mfi</th>\n",
       "      <th>mfi_signal</th>\n",
       "      <th>roc</th>\n",
       "      <th>roc_signal</th>\n",
       "      <th>rsi</th>\n",
       "      <th>rsi_signal</th>\n",
       "      <th>ult_osc</th>\n",
       "      <th>ult_signal</th>\n",
       "      <th>willr</th>\n",
       "      <th>wr_signal</th>\n",
       "      <th>ad_osc</th>\n",
       "      <th>ad_signal</th>\n",
       "      <th>stoch_slowk</th>\n",
       "      <th>stoch_slowd</th>\n",
       "      <th>sslow_signal</th>\n",
       "      <th>stoch_fastk</th>\n",
       "      <th>stoch_fastd</th>\n",
       "      <th>srsi_signal</th>\n",
       "      <th>trix</th>\n",
       "      <th>trix_signal</th>\n",
       "      <th>sr_pivotpts</th>\n",
       "      <th>sr_res1</th>\n",
       "      <th>sr_sup1</th>\n",
       "      <th>sr_res2</th>\n",
       "      <th>sr_sup2</th>\n",
       "      <th>sr_res3</th>\n",
       "      <th>sr_sup3</th>\n",
       "      <th>cv_signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>-1.169181</td>\n",
       "      <td>-1.157299</td>\n",
       "      <td>-1.15216</td>\n",
       "      <td>-1.118360</td>\n",
       "      <td>0.639008</td>\n",
       "      <td>20.680000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.006326</td>\n",
       "      <td>18.719999</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.089051</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.321332</td>\n",
       "      <td>-1.279148</td>\n",
       "      <td>-1.221656</td>\n",
       "      <td>1.341702</td>\n",
       "      <td>-0.221542</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.460919</td>\n",
       "      <td>-1.606757</td>\n",
       "      <td>-1.590867</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.591087</td>\n",
       "      <td>-1.687069</td>\n",
       "      <td>-1.676153</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.257753</td>\n",
       "      <td>1</td>\n",
       "      <td>1.219553</td>\n",
       "      <td>1.264466</td>\n",
       "      <td>-1.068669</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.313898</td>\n",
       "      <td>1</td>\n",
       "      <td>1.004782</td>\n",
       "      <td>1</td>\n",
       "      <td>1.390227</td>\n",
       "      <td>1.549988</td>\n",
       "      <td>-0.096380</td>\n",
       "      <td>0</td>\n",
       "      <td>1.164215</td>\n",
       "      <td>1</td>\n",
       "      <td>1.561731</td>\n",
       "      <td>0</td>\n",
       "      <td>1.442156</td>\n",
       "      <td>0</td>\n",
       "      <td>1.356830</td>\n",
       "      <td>0</td>\n",
       "      <td>0.191720</td>\n",
       "      <td>0</td>\n",
       "      <td>1.334246</td>\n",
       "      <td>0</td>\n",
       "      <td>1.564001</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.269844</td>\n",
       "      <td>-0.148049</td>\n",
       "      <td>0</td>\n",
       "      <td>0.698039</td>\n",
       "      <td>-0.732738</td>\n",
       "      <td>0</td>\n",
       "      <td>1.451422</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.142985</td>\n",
       "      <td>-0.827349</td>\n",
       "      <td>-0.890331</td>\n",
       "      <td>-1.051099</td>\n",
       "      <td>-1.175919</td>\n",
       "      <td>-0.728905</td>\n",
       "      <td>-0.909411</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>-1.101747</td>\n",
       "      <td>-1.098349</td>\n",
       "      <td>-1.09877</td>\n",
       "      <td>-1.081848</td>\n",
       "      <td>2.142760</td>\n",
       "      <td>20.340000</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.016441</td>\n",
       "      <td>18.900000</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.086074</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.296796</td>\n",
       "      <td>-1.260871</td>\n",
       "      <td>-1.209938</td>\n",
       "      <td>1.443046</td>\n",
       "      <td>-0.155418</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.444752</td>\n",
       "      <td>-1.598041</td>\n",
       "      <td>-1.584059</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.563987</td>\n",
       "      <td>-1.675790</td>\n",
       "      <td>-1.662338</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.241792</td>\n",
       "      <td>1</td>\n",
       "      <td>1.295293</td>\n",
       "      <td>1.656456</td>\n",
       "      <td>-1.216766</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.378875</td>\n",
       "      <td>1</td>\n",
       "      <td>1.253799</td>\n",
       "      <td>1</td>\n",
       "      <td>1.457677</td>\n",
       "      <td>1.555591</td>\n",
       "      <td>0.078078</td>\n",
       "      <td>1</td>\n",
       "      <td>1.171118</td>\n",
       "      <td>1</td>\n",
       "      <td>1.645223</td>\n",
       "      <td>0</td>\n",
       "      <td>1.297461</td>\n",
       "      <td>0</td>\n",
       "      <td>1.505069</td>\n",
       "      <td>0</td>\n",
       "      <td>0.626544</td>\n",
       "      <td>0</td>\n",
       "      <td>1.120493</td>\n",
       "      <td>0</td>\n",
       "      <td>1.930265</td>\n",
       "      <td>1</td>\n",
       "      <td>0.257237</td>\n",
       "      <td>-0.227046</td>\n",
       "      <td>0</td>\n",
       "      <td>1.139066</td>\n",
       "      <td>0.256536</td>\n",
       "      <td>0</td>\n",
       "      <td>1.519308</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.093350</td>\n",
       "      <td>-0.737175</td>\n",
       "      <td>-0.851602</td>\n",
       "      <td>-0.950513</td>\n",
       "      <td>-1.179561</td>\n",
       "      <td>-0.593715</td>\n",
       "      <td>-0.921427</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>-1.070840</td>\n",
       "      <td>-1.106770</td>\n",
       "      <td>-1.15216</td>\n",
       "      <td>-1.177339</td>\n",
       "      <td>1.022456</td>\n",
       "      <td>20.260000</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.003933</td>\n",
       "      <td>18.600000</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.085546</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.287113</td>\n",
       "      <td>-1.253220</td>\n",
       "      <td>-1.204436</td>\n",
       "      <td>0.550893</td>\n",
       "      <td>-0.134384</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.433052</td>\n",
       "      <td>-1.590782</td>\n",
       "      <td>-1.578353</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.545047</td>\n",
       "      <td>-1.666641</td>\n",
       "      <td>-1.653785</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.217674</td>\n",
       "      <td>1</td>\n",
       "      <td>1.252893</td>\n",
       "      <td>1.079920</td>\n",
       "      <td>-0.845719</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.313898</td>\n",
       "      <td>1</td>\n",
       "      <td>0.658914</td>\n",
       "      <td>1</td>\n",
       "      <td>1.379371</td>\n",
       "      <td>1.543035</td>\n",
       "      <td>-0.108883</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160075</td>\n",
       "      <td>1</td>\n",
       "      <td>1.403751</td>\n",
       "      <td>0</td>\n",
       "      <td>0.314070</td>\n",
       "      <td>0</td>\n",
       "      <td>0.703464</td>\n",
       "      <td>0</td>\n",
       "      <td>0.062437</td>\n",
       "      <td>0</td>\n",
       "      <td>0.212042</td>\n",
       "      <td>0</td>\n",
       "      <td>1.387529</td>\n",
       "      <td>1</td>\n",
       "      <td>0.803962</td>\n",
       "      <td>0.284918</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.973098</td>\n",
       "      <td>0.361669</td>\n",
       "      <td>1</td>\n",
       "      <td>1.580734</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.145794</td>\n",
       "      <td>-0.878748</td>\n",
       "      <td>-0.952477</td>\n",
       "      <td>-1.042869</td>\n",
       "      <td>-1.189577</td>\n",
       "      <td>-0.767654</td>\n",
       "      <td>-0.978934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>-1.177611</td>\n",
       "      <td>-1.205021</td>\n",
       "      <td>-1.18307</td>\n",
       "      <td>-1.199808</td>\n",
       "      <td>0.113814</td>\n",
       "      <td>20.110001</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.007404</td>\n",
       "      <td>18.570000</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.083416</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.284341</td>\n",
       "      <td>-1.244436</td>\n",
       "      <td>-1.189654</td>\n",
       "      <td>0.302612</td>\n",
       "      <td>-0.202750</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.422711</td>\n",
       "      <td>-1.583935</td>\n",
       "      <td>-1.572947</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.525456</td>\n",
       "      <td>-1.658651</td>\n",
       "      <td>-1.645185</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.195968</td>\n",
       "      <td>1</td>\n",
       "      <td>1.153228</td>\n",
       "      <td>0.830531</td>\n",
       "      <td>-0.626599</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.248921</td>\n",
       "      <td>1</td>\n",
       "      <td>0.087822</td>\n",
       "      <td>1</td>\n",
       "      <td>1.273312</td>\n",
       "      <td>1.509911</td>\n",
       "      <td>-0.320626</td>\n",
       "      <td>0</td>\n",
       "      <td>1.071905</td>\n",
       "      <td>1</td>\n",
       "      <td>1.155536</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.190918</td>\n",
       "      <td>0</td>\n",
       "      <td>0.532015</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.094744</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001712</td>\n",
       "      <td>0</td>\n",
       "      <td>0.971730</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.050296</td>\n",
       "      <td>0.363990</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.224255</td>\n",
       "      <td>-0.442993</td>\n",
       "      <td>1</td>\n",
       "      <td>1.634198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.196366</td>\n",
       "      <td>-0.976136</td>\n",
       "      <td>-1.049750</td>\n",
       "      <td>-1.092248</td>\n",
       "      <td>-1.238745</td>\n",
       "      <td>-0.860651</td>\n",
       "      <td>-1.071632</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>-1.202899</td>\n",
       "      <td>-1.241514</td>\n",
       "      <td>-1.22241</td>\n",
       "      <td>-1.241936</td>\n",
       "      <td>0.324656</td>\n",
       "      <td>20.150000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.085032</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.286142</td>\n",
       "      <td>-1.238202</td>\n",
       "      <td>-1.175341</td>\n",
       "      <td>-0.118472</td>\n",
       "      <td>-0.292838</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.414467</td>\n",
       "      <td>-1.577770</td>\n",
       "      <td>-1.568050</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.511082</td>\n",
       "      <td>-1.651729</td>\n",
       "      <td>-1.637589</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.000611</td>\n",
       "      <td>0</td>\n",
       "      <td>0.987992</td>\n",
       "      <td>0.570148</td>\n",
       "      <td>-0.335794</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.183944</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.563369</td>\n",
       "      <td>1</td>\n",
       "      <td>1.123685</td>\n",
       "      <td>1.450854</td>\n",
       "      <td>-0.587622</td>\n",
       "      <td>0</td>\n",
       "      <td>0.933880</td>\n",
       "      <td>1</td>\n",
       "      <td>1.037445</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.128574</td>\n",
       "      <td>0</td>\n",
       "      <td>0.216803</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.062344</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.417092</td>\n",
       "      <td>0</td>\n",
       "      <td>0.579160</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.024149</td>\n",
       "      <td>-0.097513</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.224255</td>\n",
       "      <td>-1.432267</td>\n",
       "      <td>1</td>\n",
       "      <td>1.677407</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.235698</td>\n",
       "      <td>-1.051881</td>\n",
       "      <td>-1.125406</td>\n",
       "      <td>-1.130653</td>\n",
       "      <td>-1.276986</td>\n",
       "      <td>-0.932983</td>\n",
       "      <td>-1.143730</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date      open      high      low     close    volume    close_1 result_1    perf_1   close_14 result_14   perf_14  results  bb_upper  bb_middle  bb_lower    bb_pct  bb_bandwidth bb_squeeze bb_signalup bb_signaldn  bb_signal     ema50    ema150    ema200  ema_signal1  ema_signal2    kama50   kama150   kama200  kama_signal1  kama_signal2       sar  sar_signal       adx   plus_di  minus_di adx_trend adx_direction  adx_signal  aroon_osc  aroon_signal       cci  cci_signal      macd  \\\n",
       "0 2010-01-04 -1.169181 -1.157299 -1.15216 -1.118360  0.639008  20.680000     True  0.006326  18.719999     False -0.089051        0 -1.321332  -1.279148 -1.221656  1.341702     -0.221542      False        True       False          0 -1.460919 -1.606757 -1.590867            1            1 -1.591087 -1.687069 -1.676153             1             1 -1.257753           1  1.219553  1.264466 -1.068669      True          True           1   1.313898             1  1.004782           1  1.390227   \n",
       "1 2010-01-05 -1.101747 -1.098349 -1.09877 -1.081848  2.142760  20.340000    False -0.016441  18.900000     False -0.086074        0 -1.296796  -1.260871 -1.209938  1.443046     -0.155418      False        True       False          0 -1.444752 -1.598041 -1.584059            1            1 -1.563987 -1.675790 -1.662338             1             1 -1.241792           1  1.295293  1.656456 -1.216766      True          True           1   1.378875             1  1.253799           1  1.457677   \n",
       "2 2010-01-06 -1.070840 -1.106770 -1.15216 -1.177339  1.022456  20.260000    False -0.003933  18.600000     False -0.085546        0 -1.287113  -1.253220 -1.204436  0.550893     -0.134384      False       False       False          0 -1.433052 -1.590782 -1.578353            1            1 -1.545047 -1.666641 -1.653785             1             1 -1.217674           1  1.252893  1.079920 -0.845719      True          True           1   1.313898             1  0.658914           1  1.379371   \n",
       "3 2010-01-07 -1.177611 -1.205021 -1.18307 -1.199808  0.113814  20.110001    False -0.007404  18.570000     False -0.083416        0 -1.284341  -1.244436 -1.189654  0.302612     -0.202750      False       False       False          0 -1.422711 -1.583935 -1.572947            1            1 -1.525456 -1.658651 -1.645185             1             1 -1.195968           1  1.153228  0.830531 -0.626599      True          True           1   1.248921             1  0.087822           1  1.273312   \n",
       "4 2010-01-08 -1.202899 -1.241514 -1.22241 -1.241936  0.324656  20.150000     True  0.001989  18.400000     False -0.085032        0 -1.286142  -1.238202 -1.175341 -0.118472     -0.292838      False       False       False          0 -1.414467 -1.577770 -1.568050            1            1 -1.511082 -1.651729 -1.637589             1             1 -1.000611           0  0.987992  0.570148 -0.335794      True          True           1   1.183944             1 -0.563369           1  1.123685   \n",
       "\n",
       "   macd_sigline  macd_hist  macd_signal       ppo  ppo_signal       mfi  mfi_signal       roc  roc_signal       rsi  rsi_signal   ult_osc  ult_signal     willr  wr_signal    ad_osc  ad_signal  stoch_slowk  stoch_slowd  sslow_signal  stoch_fastk  stoch_fastd  srsi_signal      trix  trix_signal  sr_pivotpts   sr_res1   sr_sup1   sr_res2   sr_sup2   sr_res3   sr_sup3  cv_signal  \n",
       "0      1.549988  -0.096380            0  1.164215           1  1.561731           0  1.442156           0  1.356830           0  0.191720           0  1.334246          0  1.564001          1    -0.269844    -0.148049             0     0.698039    -0.732738            0  1.451422            1    -1.142985 -0.827349 -0.890331 -1.051099 -1.175919 -0.728905 -0.909411          0  \n",
       "1      1.555591   0.078078            1  1.171118           1  1.645223           0  1.297461           0  1.505069           0  0.626544           0  1.120493          0  1.930265          1     0.257237    -0.227046             0     1.139066     0.256536            0  1.519308            1    -1.093350 -0.737175 -0.851602 -0.950513 -1.179561 -0.593715 -0.921427          0  \n",
       "2      1.543035  -0.108883            0  1.160075           1  1.403751           0  0.314070           0  0.703464           0  0.062437           0  0.212042          0  1.387529          1     0.803962     0.284918             0    -0.973098     0.361669            1  1.580734            1    -1.145794 -0.878748 -0.952477 -1.042869 -1.189577 -0.767654 -0.978934          0  \n",
       "3      1.509911  -0.320626            0  1.071905           1  1.155536           0 -0.190918           0  0.532015           0 -0.094744           0 -0.001712          0  0.971730          1    -0.050296     0.363990             0    -1.224255    -0.442993            1  1.634198            1    -1.196366 -0.976136 -1.049750 -1.092248 -1.238745 -0.860651 -1.071632          1  \n",
       "4      1.450854  -0.587622            0  0.933880           1  1.037445           0 -0.128574           0  0.216803           0 -0.062344           0 -0.417092          0  0.579160          1    -1.024149    -0.097513             0    -1.224255    -1.432267            1  1.677407            1    -1.235698 -1.051881 -1.125406 -1.130653 -1.276986 -0.932983 -1.143730          0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code here\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(dftouse[mask][STANDARDIZABLE])\n",
    "dftouse[STANDARDIZABLE] = scaler.transform(dftouse[STANDARDIZABLE])\n",
    "dftouse.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a list `lcols` of the columns we will use in our classifier. This list should not contain the response `RESP`. How many features do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "#lcols=list(dftouse.columns)\n",
    "#lcols.remove(u'results')\n",
    "lcols=[]\n",
    "for c in list(dftouse.columns):\n",
    "    if c not in IGNORE: \n",
    "        lcols.append(c)\n",
    "print len(lcols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA for the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We create a variable `ccols` which contains all variables not in our indicators list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 26\n"
     ]
    }
   ],
   "source": [
    "ccols=[]\n",
    "for c in lcols:\n",
    "    if c not in INDICATORS and c not in IGNORE:\n",
    "        ccols.append(c)\n",
    "print len(ccols), len(INDICATORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_optimize(clf, parameters, X, y, n_folds, score_func):\n",
    "    fitmodel = GridSearchCV(clf, param_grid=parameters, cv=n_folds, scoring=score_func)\n",
    "    fitmodel.fit(X, y)\n",
    "    return fitmodel.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def do_classify(clf, parameters, indf, featurenames, targetname, target1val, mask=None, reuse_split=None, score_func=None, n_folds=5):\n",
    "    subdf=indf[featurenames]\n",
    "    X=subdf.values\n",
    "    y=(indf[targetname].values==target1val)*1\n",
    "    if mask !=None:\n",
    "        #print \"using mask\"\n",
    "        Xtrain, Xtest, ytrain, ytest = X[mask], X[~mask], y[mask], y[~mask]\n",
    "    if reuse_split !=None:\n",
    "        #print \"using reuse split\"\n",
    "        Xtrain, Xtest, ytrain, ytest = reuse_split['Xtrain'], reuse_split['Xtest'], reuse_split['ytrain'], reuse_split['ytest']\n",
    "    if parameters:\n",
    "        clf = cv_optimize(clf, parameters, Xtrain, ytrain, n_folds=n_folds, score_func=score_func)\n",
    "    clf=clf.fit(Xtrain, ytrain)\n",
    "    training_accuracy = clf.score(Xtrain, ytrain)\n",
    "    test_accuracy = clf.score(Xtest, ytest)\n",
    "    #print \"############# based on standard predict ################\"\n",
    "    #print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
    "    #print \"Accuracy on test data:     %0.2f\" % (test_accuracy)\n",
    "    #print confusion_matrix(ytest, clf.predict(Xtest))\n",
    "    #print \"########################################################\"\n",
    "    return clf, Xtrain, ytrain, Xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=dftouse[lcols].values\n",
    "y=dftouse['results'].values\n",
    "Xtrain, Xtest, ytrain, ytest = X[mask], X[~mask], y[mask], y[~mask]  \n",
    "reuse_split=dict(Xtrain=Xtrain, Xtest=Xtest, ytrain=ytrain, ytest=ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whole data set 0.465366509751\n",
      "training set 0.467408585056 test set 0.454148471616\n"
     ]
    }
   ],
   "source": [
    "print \"whole data set\", dftouse['results'].mean()\n",
    "print \"training set\", dftouse['results'][mask].mean(), \"test set\", dftouse['results'][~mask].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####our data is not very asymmetric, but we might still want to balance the trainset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing train set to test set for training, \n",
    "### intended to be used with SVM only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "588 670\n",
      "(1176L, 70L) (1176L,)\n"
     ]
    }
   ],
   "source": [
    "jtrain=np.arange(0, ytrain.shape[0])\n",
    "n_pos=len(jtrain[ytrain==1])\n",
    "n_neg=len(jtrain[ytrain==0])\n",
    "print n_pos, n_neg\n",
    "\n",
    "ineg = np.random.choice(jtrain[ytrain==0], n_pos, replace=False)\n",
    "alli=np.concatenate((jtrain[ytrain==1], ineg))\n",
    "Xtrain_new = Xtrain[alli]\n",
    "ytrain_new = ytrain[alli]\n",
    "print Xtrain_new.shape, ytrain_new.shape\n",
    "\n",
    "reuse_split_balanced=dict(Xtrain=Xtrain_new, Xtest=Xtest, ytrain=ytrain_new, ytest=ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test all classifiersres using SelectKbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def evaluate(clf):\n",
    "    training_accuracy = clf.score(Xtrain, ytrain)\n",
    "    test_accuracy = clf.score(Xtest, ytest)\n",
    "    df_pred = df[~mask].reset_index(drop=True)\n",
    "    df_pred['pred_result'] = clf.predict(Xtest)\n",
    "    df_pred['result_baseline'] = np.ones(df_pred.shape[0])\n",
    "    _,_,ROI_base,_,_ = evaluate_profit(df_pred, startdate, enddate, 10000, 'result_baseline', 'close', False, [1])\n",
    "    _,_,ROI_long,_,_ = evaluate_profit(df_pred, startdate, enddate, 10000, 'pred_result', 'close', False, [1])\n",
    "    _,_,ROI_lgst,_,_ = evaluate_profit(df_pred, startdate, enddate, 10000, 'pred_result', 'close', False, [1,0])\n",
    "    return training_accuracy, test_accuracy, ROI_base, ROI_long, ROI_lgst\n",
    "\n",
    "def print_result(clfpipe):     \n",
    "    print \"Number of features: {0}\".format(clfpipe.get_params()['selectk__k'])\n",
    "    print \"Features: {0}\".format(np.array(lcols)[clfpipe.named_steps['selectk'].get_support()].tolist())\n",
    "    r = evaluate(clfpipe)\n",
    "    print \"train accuracy: {0}\".format(r[0])\n",
    "    print \"test accuracy: {0}\".format(r[1])\n",
    "    print \"ROI baseline: {0}\".format(r[2])\n",
    "    print \"ROI long-only: {0}\".format(r[3])\n",
    "    print \"ROI long-short: {0}\".format(r[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############====================== Log Regression =====================#############\n",
      "0.1\n",
      "Number of features: 4\n",
      "Features: ['bb_pct', 'cci', 'rsi', 'stoch_slowk']\n",
      "train accuracy: 0.693958664547\n",
      "test accuracy: 0.711790393013\n",
      "ROI baseline: 0.014620034\n",
      "ROI long-only: 0.1681285893\n",
      "ROI long-short: 0.3389570549\n",
      "Wall time: 2.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_number_featrues = 10 \n",
    "Long_ROI_result={}\n",
    "print \"#############====================== Log Regression =====================#############\"\n",
    "selectk = SelectKBest(score_func=f_regression)\n",
    "pipeLR = Pipeline([('selectk', selectk), ('LR', LogisticRegression(penalty=\"l1\"))])\n",
    "pipeLR, _,_,_,_  = do_classify(pipeLR, {\"selectk__k\":range(1,max_number_featrues+1), \n",
    "                                        \"LR__C\": [1e-3, 1e-2, 1e-1, 1, 1e2]}, \n",
    "                               dftouse,lcols, u'results',1, reuse_split=reuse_split)\n",
    "\n",
    "print pipeLR.get_params()['LR__C']\n",
    "print_result(pipeLR)\n",
    "Long_ROI_result[\"log_regression\"] = evaluate(pipeLR)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############====================== Linear SVM ========================#############\n",
      "1e-300\n",
      "Number of features: 2\n",
      "Features: ['rsi', 'stoch_slowk']\n",
      "train accuracy: 0.680445151033\n",
      "test accuracy: 0.689956331878\n",
      "ROI baseline: 0.014620034\n",
      "ROI long-only: 0.1048287143\n",
      "ROI long-short: 0.1973673615\n",
      "Wall time: 2.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print \"#############====================== Linear SVM ========================#############\"\n",
    "clfsvm_b = Pipeline([('selectk', selectk), ('svm', LinearSVC(loss=\"hinge\"))])\n",
    "clfsvm_b,_,_,_,_  = do_classify(clfsvm_b, {\"selectk__k\":range(1,max_number_featrues+1), \n",
    "                                           \"svm__C\": [1e-300, 1e-200, 1e-100, 1e-10, 1e-1, 1]}, \n",
    "                                dftouse,lcols, u'results',1, reuse_split=reuse_split_balanced)\n",
    "\n",
    "print clfsvm_b.get_params()['svm__C']\n",
    "print_result(clfsvm_b)\n",
    "Long_ROI_result[\"Linear_SVM\"] = evaluate(clfsvm_b)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############====================== RBF SVM ===========================#############\n",
      "1e-100 1e-09\n",
      "Number of features: 2\n",
      "Features: ['rsi', 'stoch_slowk']\n",
      "train accuracy: 0.689189189189\n",
      "test accuracy: 0.698689956332\n",
      "ROI baseline: 0.014620034\n",
      "ROI long-only: 0.1476656346\n",
      "ROI long-short: 0.2916491734\n",
      "Wall time: 28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print \"#############====================== RBF SVM ===========================#############\"\n",
    "pipesvm2 = Pipeline([('selectk', selectk), ('svm2', SVC())])\n",
    "pipesvm2,_,_,_,_  = do_classify(pipesvm2, {\"selectk__k\":range(1,max_number_featrues+1), \n",
    "                                            \"svm2__C\": [1e-100, 1e-10, 1e-1, 1, 1e10], \n",
    "                                            \"svm2__gamma\": [ 1e-9, 1e-10, 1e-11]}, \n",
    "                                 dftouse,lcols, u'results',1, reuse_split=reuse_split_balanced)\n",
    "print pipesvm2.get_params()['svm2__C'], pipesvm2.get_params()['svm2__gamma']\n",
    "print_result(pipesvm2)\n",
    "Long_ROI_result[\"RBF_SVM\"] = evaluate(pipesvm2)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############====================== Random Forest =====================#############\n",
      "3 5 1\n",
      "Number of features: 9\n",
      "Features: ['bb_pct', 'plus_di', 'cci', 'rsi', 'ult_osc', 'willr', 'stoch_slowk', 'stoch_slowd', 'stoch_fastd']\n",
      "train accuracy: 0.698728139905\n",
      "test accuracy: 0.681222707424\n",
      "ROI baseline: 0.014620034\n",
      "ROI long-only: 0.0804786029\n",
      "ROI long-short: 0.1471181214\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print \"#############====================== Random Forest =====================#############\"\n",
    "pipeRF = Pipeline([('selectk', selectk), ('RF', RandomForestClassifier())])\n",
    "pipeRF,_,_,_,_  = do_classify(pipeRF, {\"selectk__k\": [5,6,7,8,9,10],\n",
    "                                       \"RF__max_depth\": [3,5,7,10], \n",
    "                                       \"RF__n_estimators\": [5,10,20,40],\n",
    "                                       \"RF__max_features\": [1,2,3,4,5]}, \n",
    "                              dftouse, lcols, u'results', 1, reuse_split=reuse_split)\n",
    "\n",
    "print pipeRF.get_params()['RF__max_depth'], pipeRF.get_params()['RF__n_estimators'], pipeRF.get_params()['RF__max_features']\n",
    "print_result(pipeRF)\n",
    "Long_ROI_result[\"Random_forest\"] = evaluate(pipeRF)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############====================== Extra Trees= =====================#############\n",
      "ET__max_depth: 7\n",
      "ET__n_estimators: 40\n",
      "ET__max_features: 4\n",
      "Number of features: 10\n",
      "Features: ['bb_pct', 'plus_di', 'minus_di', 'cci', 'rsi', 'ult_osc', 'willr', 'stoch_slowk', 'stoch_slowd', 'stoch_fastd']\n",
      "train accuracy: 0.780604133545\n",
      "test accuracy: 0.689956331878\n",
      "ROI baseline: 0.014620034\n",
      "ROI long-only: 0.1210777426\n",
      "ROI long-short: 0.232632404\n",
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print \"#############====================== Extra Trees= =====================#############\"\n",
    "pipeET = Pipeline([('selectk', selectk), ('ET', ExtraTreesClassifier())])\n",
    "pipeET, _,_,_,_  = do_classify(pipeET, {\"selectk__k\": [5,6,7,8,9,10],\n",
    "                                        \"ET__max_depth\": [3,5,7,10,15,25,50], \n",
    "                                        \"ET__n_estimators\": [5,10,20,40],\n",
    "                                        \"ET__max_features\": [1,2,3,4,5]}, \n",
    "                               dftouse, lcols, u'results', 1, reuse_split=reuse_split)\n",
    "print \"ET__max_depth: {0}\".format(pipeET.get_params()['ET__max_depth']) \n",
    "print \"ET__n_estimators: {0}\".format(pipeET.get_params()['ET__n_estimators']) \n",
    "print \"ET__max_features: {0}\".format(pipeET.get_params()['ET__max_features']) \n",
    "print_result(pipeET)\n",
    "Long_ROI_result[\"Extra_Trees\"] = evaluate(pipeET)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############====================== Gaussian NB ==========================#############\n",
      "Number of features: 5\n",
      "Features: ['bb_pct', 'plus_di', 'cci', 'rsi', 'stoch_slowk']\n",
      "train accuracy: 0.690779014308\n",
      "test accuracy: 0.676855895197\n",
      "ROI baseline: 0.014620034\n",
      "ROI long-only: 0.0934196795\n",
      "ROI long-short: 0.1745582902\n",
      "Wall time: 491 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print \"#############====================== Gaussian NB ==========================#############\"\n",
    "pipeNB = Pipeline([('selectk', selectk), ('NB', GaussianNB())])\n",
    "pipeNB,_,_,_,_ = do_classify(pipeNB, {\"selectk__k\":range(1,max_number_featrues+1)},\n",
    "                             dftouse, lcols, u'results',1, reuse_split=reuse_split)\n",
    "print_result(pipeNB)\n",
    "Long_ROI_result[\"Gaussian_NB\"] = evaluate(pipeNB)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############====================== Gradient Boosting ====================#############\n",
      "20 0.1\n",
      "Number of features: 5\n",
      "Features: ['bb_pct', 'plus_di', 'cci', 'rsi', 'stoch_slowk']\n",
      "train accuracy: 0.743243243243\n",
      "test accuracy: 0.663755458515\n",
      "ROI baseline: 0.014620034\n",
      "ROI long-only: 0.1203037765\n",
      "ROI long-short: 0.2309004705\n",
      "Wall time: 20.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print \"#############====================== Gradient Boosting ====================#############\"\n",
    "pipeGB = Pipeline([('selectk', selectk), ('GB', GradientBoostingClassifier())])\n",
    "pipeGB, _,_,_,_  = do_classify(pipeGB, {\"selectk__k\":range(1,max_number_featrues+1), \n",
    "                                        \"GB__n_estimators\": [5,10,20,40],\n",
    "                                        \"GB__learning_rate\": [0.1,0.5,1.0]}, \n",
    "                               dftouse,lcols, u'results',1, reuse_split=reuse_split)\n",
    "print pipeGB.get_params()['GB__n_estimators'], pipeGB.get_params()['GB__learning_rate']\n",
    "print_result(pipeGB)\n",
    "Long_ROI_result[\"Gradient_bossting\"] = evaluate(pipeGB)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROI baseline: 0.014620034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Extra_Trees': 0.12107774259999933,\n",
       " 'Gaussian_NB': 0.093419679499999977,\n",
       " 'Gradient_bossting': 0.12030377649999974,\n",
       " 'Linear_SVM': 0.10482871430000014,\n",
       " 'RBF_SVM': 0.14766563460000051,\n",
       " 'Random_forest': 0.080478602900000085,\n",
       " 'log_regression': 0.16812858929999966}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"ROI baseline: {0}\".format(evaluate(pipeGB)[2])\n",
    "Long_ROI_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
